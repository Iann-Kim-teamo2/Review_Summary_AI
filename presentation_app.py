import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import math # Added for weighting calculation
from advanced_process_reviews import AdvancedReviewProcessor, POS_ANCHOR, NEG_ANCHOR

import os
import datetime # Added to fix NameError
from dotenv import load_dotenv
import google.generativeai as genai

# Load Environment Variables
load_dotenv()

# Page Config
st.set_page_config(page_title="AI Review Analysis Presentation", layout="wide")

# Load Data
# Removed @st.cache_data to ensure fresh load during development
def load_data():
    with open('refined_reviews_advanced.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

data = load_data()
df = pd.DataFrame(data)

# === Global Data Preprocessing ===
# 1. Ensure 'ì‘ì„±ì¼' (Date)
today = datetime.date.today()
if 'ì‘ì„±ì¼' not in df.columns:
    df['ì‘ì„±ì¼'] = [today.strftime("%Y-%m-%d")] * len(df)
df['ì‘ì„±ì¼'] = pd.to_datetime(df['ì‘ì„±ì¼'], errors='coerce')

# 2. Ensure 'ê³µê°ìˆ˜' (Likes)
if 'ê³µê°ìˆ˜' not in df.columns:
    df['ê³µê°ìˆ˜'] = 0
df['ê³µê°ìˆ˜'] = pd.to_numeric(df['ê³µê°ìˆ˜'], errors='coerce').fillna(0).astype(int)

# === Gemini AI Logic ===
def generate_ai_report(df):
    """
    í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Geminiì—ê²Œ ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    # 1. Try Streamlit Secrets (Cloud)
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        # 2. Fallback to Environment Variable (Local .env)
        api_key = os.getenv("GEMINI_API_KEY")

    if not api_key or api_key == "YOUR_API_KEY_HERE":
        return None
    
    genai.configure(api_key=api_key)
    # Using gemini-1.5-flash for speed and stability
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    # 1. Prepare Prompt
    total_reviews = len(df)
    avg_rating = df['ë³„ì '].astype(int).mean()
    
    # Extract Tags
    all_tags = []
    for tags in df['íƒœê·¸_ABSA']:
        all_tags.extend(tags)
    tag_counts = pd.Series(all_tags).value_counts().head(5).to_string()
    
    prompt = f"""
    ë‹¹ì‹ ì€ ë Œí„°ì¹´ ì„œë¹„ìŠ¤ ë¦¬ë·° ë¶„ì„ AIì…ë‹ˆë‹¤.
    ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ 'ì§ê´€ì ì¸ ìš”ì•½ ì¹´ë“œ' ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ë¶„ì„ ë°ì´í„°]
    - ì´ ë¦¬ë·° ìˆ˜: {total_reviews}ê±´
    - í‰ê·  í‰ì : {avg_rating:.2f} / 5.0
    - ì£¼ìš” íƒœê·¸(Top 5):
    {tag_counts}

    [ì‘ì„± ìš”êµ¬ì‚¬í•­]
    ì•„ë˜ 5ê°€ì§€ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”. ê° í•­ëª© ì‚¬ì´ì—ëŠ” êµ¬ë¶„ì„ (---)ì„ ë„£ì§€ ë§ˆì„¸ìš”.
    
    1. **í•œ ì¤„ ìš”ì•½**: ì „ì²´ì ì¸ ê³ ê° ë°˜ì‘ì„ 20ì ë‚´ì™¸ì˜ ë§¤ë ¥ì ì¸ ë¬¸êµ¬ë¡œ ìš”ì•½ (ì˜ˆ: "ì‚°ëœ»í•œ ì‚¬ìš©ê°, íŠ¸ëŸ¬ë¸” ê±±ì • ì—†ëŠ” ìˆ˜ë¶„ í† ë„ˆ!")
    2. **ï¿½ ê¸ì • ë¦¬ë·° ìš”ì•½**: ê³ ê°ë“¤ì´ ë§Œì¡±í•œ ì ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ  (ì´ëª¨ì§€ 'ï¿½'ë¡œ ì‹œì‘, ì¸ìš©êµ¬ ì‚¬ìš©)
    3. **ğŸ’­ ì•„ì‰¬ìš´ ì  ìš”ì•½**: ê°œì„ ì´ í•„ìš”í•œ ì ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ì„œìˆ  (ìƒ‰ ë‹¤ë¥¸ ê¸€ì”¨ì²´ë‚˜ ì¸ìš©êµ¬ ì‚¬ìš©)
    4. **ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ**: ì£¼ìš” íƒœê·¸ 5ê°œë¥¼ ë‚˜ì—´ (ì˜ˆ: ` #ì¹œì ˆ ` ` #ì²­ê²° `)
    5. **ì¢…í•© ê°ì„± ë¶„ì„**: ê¸ì • ë¹„ìœ¨ì´ë‚˜ ì „ë°˜ì ì¸ ë§Œì¡±ë„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬ (ì˜ˆ: "ê¸ì • ë¦¬ë·° 85%, ëŒ€ë¶€ë¶„ì˜ ê³ ê°ë“¤ì´ ë§Œì¡±í–ˆì–´ìš”!")

    [ì¶œë ¥ í¬ë§· ì˜ˆì‹œ]
    ### (í•œ ì¤„ ìš”ì•½ ë‚´ìš©)
    
    > ğŸ‘ (ê¸ì • ìš”ì•½ ë‚´ìš©...)
    
    > (ì•„ì‰¬ìš´ ì  ìš”ì•½ ë‚´ìš©...)
    
    `#í‚¤ì›Œë“œ1` `#í‚¤ì›Œë“œ2` `#í‚¤ì›Œë“œ3` `#í‚¤ì›Œë“œ4` `#í‚¤ì›Œë“œ5`
    
    **(ì¢…í•© ê°ì„± ë¶„ì„ ë‚´ìš©)**
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error creating report: {str(e)}"

# Tabs
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ§© ë¶„ì„ ì›ë¦¬ (How it Works)", "ğŸ§ª ì‹¤ì‹œê°„ ì²´í—˜ (Live Demo)"])

# === Tab 1: Dashboard ===
with tab1:
    st.header("ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # --- AI Report Section ---
    st.markdown("### ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸")
    
    report_file = "ai_report.md"
    
    # Try Secrets then Env
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        api_key = os.getenv("GEMINI_API_KEY")
    
    # Refresh Button
    force_refresh = st.button("ğŸ”„ ë¦¬í¬íŠ¸ ìµœì‹ í™” (Re-generate)")
    
    markdown_content = ""
    
    # 1. Load existing report if available and not forcing refresh
    if os.path.exists(report_file) and not force_refresh:
        with open(report_file, "r", encoding="utf-8") as f:
            markdown_content = f.read()
    
    # 2. Generate new report if missing or forced
    elif api_key and api_key != "YOUR_API_KEY_HERE":
        with st.spinner("Geminiê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 5~10ì´ˆ ì†Œìš”)"):
            markdown_content = generate_ai_report(df)
            if markdown_content:
                with open(report_file, "w", encoding="utf-8") as f:
                    f.write(markdown_content)
    
    # 3. Display Result
    if markdown_content:
        st.info(markdown_content)
    elif not api_key or api_key == "YOUR_API_KEY_HERE":
        st.warning("âš ï¸ Streamlit Cloudì˜ 'Secrets' ë˜ëŠ” ë¡œì»¬ `.env` íŒŒì¼ì— `GEMINI_API_KEY`ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    else:
        st.error("ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨. API Keyë‚˜ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.markdown("---") 

    # === Sidebar: Analysis Settings ===
    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        apply_weight = st.checkbox("ìµœì‹  ë¦¬ë·° ê°€ì¤‘ì¹˜ ì ìš© (Time Decay)", value=False)
        
        if apply_weight:
            half_life = st.slider("ë°˜ê°ê¸° (Half-life, ì¼)", 10, 180, 60, help="ì´ ê¸°ê°„ì´ ì§€ë‚˜ë©´ ë¦¬ë·°ì˜ ì¤‘ìš”ë„ê°€ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.")
            # Decay Constant lambda = ln(2) / half_life
            decay_lambda = 0.693 / half_life
            st.caption(f"ğŸ“‰ {half_life}ì¼ ì „ ë¦¬ë·°ëŠ” 50%ë§Œ ë°˜ì˜ë©ë‹ˆë‹¤.")

    # 1. Metrics
    col1, col2, col3 = st.columns(3)
    col1.metric("ì´ ë¶„ì„ ë¦¬ë·° ìˆ˜", f"{len(df)}ê±´")
    
    # Calculate Average Rating
    avg_rating = df['ë³„ì '].astype(int).mean()
    
    if apply_weight:
        # Weighting Calculation
        weights = []
        scores = df['ë³„ì '].astype(int).values
        golden_count = 0
        
        for idx, row in df.iterrows():
            # 1. Base Weight (Time Decay)
            weight = 1.0
            try:
                # row['ì‘ì„±ì¼'] is already a Timestamp due to global processing
                review_date = row['ì‘ì„±ì¼'].date()
                days_diff = (today - review_date).days
                # Exponential Decay
                weight = math.exp(-decay_lambda * days_diff)
            except:
                pass
            
            # 2. Golden Review Immunity (Likes >= 10 or Length >= 200)
            body_len = len(str(row.get('ë³¸ë¬¸', '')))
            likes = row['ê³µê°ìˆ˜']
            
            if likes >= 10 or body_len >= 200:
                weight = 1.0 # Immunity Activated
                golden_count += 1
                
            weights.append(weight)
                
        # Weighted Average
        weighted_sum = sum(s * w for s, w in zip(scores, weights))
        total_weight = sum(weights)
        weighted_avg = weighted_sum / total_weight if total_weight > 0 else avg_rating
        
        # Display with Delta
        delta = weighted_avg - avg_rating
        col2.metric("ë³´ì • í‰ì  (Weighted)", f"{weighted_avg:.2f}ì ", f"{delta:.2f} (ìµœì‹  íŠ¸ë Œë“œ ë°˜ì˜)")
        
        # Display Shield Count
        if golden_count > 0:
            st.sidebar.success(f"ğŸ›¡ï¸ **{golden_count}ê°œ**ì˜ 'ê³¨ë“  ë¦¬ë·°'(ê³ í’ˆì§ˆ/ì¸ê¸°)ê°€ ê°€ì¤‘ì¹˜ ê°ì†Œì—ì„œ ë³´í˜¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
    else:
        col2.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}ì ")
    
    # Flatten Tags for Analysis
    all_tags = []
    for tags in df['íƒœê·¸_ABSA']:
        all_tags.extend(tags)
    
    tag_counts = pd.Series(all_tags).value_counts().reset_index()
    tag_counts.columns = ['Tag', 'Count']
    
    # 2. Charts
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        st.subheader("AI ë¶„ì„ íƒœê·¸ ë¶„í¬")
        fig_tags = px.bar(tag_counts.head(10), x='Count', y='Tag', orientation='h', color='Count', title="Top 10 AI Tags")
        st.plotly_chart(fig_tags, use_container_width=True)
        
    with col_chart2:
        st.subheader("ë³„ì  ë¶„í¬")
        rating_counts = df['ë³„ì '].value_counts().sort_index()
        fig_rating = px.pie(values=rating_counts.values, names=rating_counts.index, title="Rating Distribution", hole=0.4)
        st.plotly_chart(fig_rating, use_container_width=True)

    # 3. Data Table
    st.subheader("ìƒì„¸ ë¦¬ë·° ë°ì´í„° (í•„í„°ë§ ê°€ëŠ¥)")
    st.dataframe(
        df,
        column_config={
            "ê³µê°ìˆ˜": st.column_config.ProgressColumn(
                "â¤ï¸ ê³µê°ìˆ˜",
                help="ì‚¬ìš©ìë“¤ì˜ ê³µê°(ì¢‹ì•„ìš”) íšŸìˆ˜",
                format="%d",
                min_value=0,
                max_value=100,
            ),
            "ì‘ì„±ì¼": st.column_config.DateColumn(
                "ğŸ“… ì‘ì„±ì¼",
                format="YYYY-MM-DD",
            ),
             "ë³„ì ": st.column_config.NumberColumn(
                "â­ ë³„ì ",
                format="%dì ",
            )
        },
        use_container_width=True
    )

# === Tab 2: How it Works ===
with tab2:
    st.header("SBERT Zero-Shot ABSA ì›ë¦¬")
    st.markdown("""
    ì´ ì‹œìŠ¤í…œì€ ë¯¸ë¦¬ í•™ìŠµëœ **SBERT (Sentence-BERT)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ê¹Šì´ ìˆê²Œ ì´í•´í•©ë‹ˆë‹¤.
    ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ, **'ì˜ë¯¸ì  ê±°ë¦¬(Semantic Distance)'**ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    """)
    
    col_desc1, col_desc2 = st.columns(2)
    with col_desc1:
        st.info("**1ë‹¨ê³„: ì†ì„± ì¶”ì¶œ (Aspect Extraction)**")
        st.markdown("- ë¦¬ë·°ì—ì„œ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì†ì„±(ì²­ê²°, ë¹„ìš©, ì‘ëŒ€ ë“±)ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.")
        st.markdown("- Fallback: ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì‚¬ì „ ì •ì˜ëœ í‚¤ì›Œë“œë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.")
        
    with col_desc2:
        st.success("**2ë‹¨ê³„: ê°ì • ë¶„ì„ (Zero-Shot Sentiment)**")
        st.markdown("- ì¶”ì¶œëœ ì†ì„±ì— ëŒ€í•´ **ê¸ì •/ë¶€ì • ì•µì»¤ ë¬¸ì¥**ê³¼ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
        st.code(f"ê¸ì • ì•µì»¤: {POS_ANCHOR}")
        st.code(f"ë¶€ì • ì•µì»¤: {NEG_ANCHOR}")
        st.markdown("ğŸ‘‰ ë” ê°€ê¹Œìš´ ìª½ì˜ ê°ì •ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤!")

# === Tab 3: Live Demo ===
with tab3:
    st.header("ğŸ§ª ì‹¤ì‹œê°„ AI ë¶„ì„ ì²´í—˜")
    st.markdown("ì§ì ‘ ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì—¬ AIê°€ ì–´ë–»ê²Œ ë¶„ì„í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    # Initialize Processor (Cached)
    @st.cache_resource
    def get_processor():
        return AdvancedReviewProcessor()
    
    processor = get_processor()
    
    # Input State Management
    if 'review_input' not in st.session_state:
        st.session_state.review_input = ""
    
    with st.form(key='analysis_form'):
        user_input = st.text_area("ë¦¬ë·° ë‚´ìš© ì…ë ¥:", key="review_input", height=100, placeholder="ì˜ˆì‹œ) ì§ì›ì€ ì¹œì ˆí•œë° ì°¨ëŠ” ì¢€ ë”ëŸ¬ì› ì–´ìš”.")
        demo_rating = st.slider("ì´ ë¦¬ë·°ì˜ ë³„ì ì€?", 1, 5, 3, help="ë³„ì ì— ë”°ë¼ ì¼ê´€ì„± ê²€ì‚¬ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
        submit_button = st.form_submit_button(label='AI ë¶„ì„ ì‹¤í–‰')
    
    if submit_button:
        with st.spinner("SBERT + KoNLPy ë¶„ì„ ì¤‘..."):
            tags = []
            results = []
            from advanced_process_reviews import MOCK_KEYWORDS
            
            # 0. ìŠ¤íŒ¸ ìš°ì„  íƒì§€
            is_spam = False
            for spam_kw in MOCK_KEYWORDS.get('ìŠ¤íŒ¸/í™ë³´', []):
                if spam_kw in user_input:
                    tags = ['ìŠ¤íŒ¸/í™ë³´']
                    is_spam = True
                    results.append({"ì†ì„±": "ìŠ¤íŒ¸ ê°ì§€", "ì¹´í…Œê³ ë¦¬": "ìŠ¤íŒ¸/í™ë³´", "ê°ì •": "ë¶€ì •", "ë¬¸ì¥": "ê´‘ê³ ì„± í‚¤ì›Œë“œ ê°ì§€ë¨"})
                    break
            
            if not is_spam:
                # 1. KoNLPy ìë™ ì†ì„± ì¶”ì¶œ
                found_aspects = processor.extract_aspects(user_input)
                
                # 2. ë§¤í•‘ ë° ê°ì •ë¶„ì„
                temp_tags = []
                for aspect in found_aspects:
                    cat = processor.map_category_sbert(aspect)
                    if cat == "ê¸°íƒ€": continue
                    if cat == "ìŠ¤íŒ¸/í™ë³´": continue
                    
                    sentiment = processor.analyze_sentiment_sbert(user_input, cat, aspect_keyword=aspect)
                    tag_str = f"{cat}({sentiment})"
                    
                    if tag_str not in temp_tags:
                        temp_tags.append(tag_str)
                        results.append({"ì†ì„±": aspect, "ì¹´í…Œê³ ë¦¬": cat, "ê°ì •": sentiment, "ë¬¸ì¥": f"...{aspect}..."})

                # 3. Consistency Check (ë³„ì  ì—°ë™)
                final_tags = []
                for t in temp_tags:
                    if demo_rating == 5 and "(ë¶€ì •)" in t: continue
                    if demo_rating == 1 and "(ê¸ì •)" in t: continue
                    final_tags.append(t)
                tags = final_tags
            
            # PII Check
            masked_input = user_input
            import re
            phone_pattern = r'010-\d{4}-\d{4}'
            if re.search(phone_pattern, masked_input):
                 masked_input = re.sub(phone_pattern, '010-****-****', masked_input)
                 st.warning("âš ï¸ ê°œì¸ì •ë³´(ì „í™”ë²ˆí˜¸)ê°€ ê°ì§€ë˜ì–´ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            st.markdown("### ë¶„ì„ ê²°ê³¼")
            st.subheader(f"ğŸ·ï¸ íƒœê·¸: {tags}")
            
            if results:
                st.table(pd.DataFrame(results))
            else:
                st.info("ê²€ì¶œëœ ì£¼ìš” ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            st.markdown("---")
            st.markdown("**ìµœì¢… ì €ì¥ë  í…ìŠ¤íŠ¸ (PII ë§ˆìŠ¤í‚¹ ì ìš©)**")
            st.code(masked_input)
