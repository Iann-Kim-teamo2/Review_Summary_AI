import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from advanced_process_reviews import AdvancedReviewProcessor, POS_ANCHOR, NEG_ANCHOR

import os
from dotenv import load_dotenv
import google.generativeai as genai

# Load Environment Variables
load_dotenv()

# Page Config
st.set_page_config(page_title="AI Review Analysis Presentation", layout="wide")

# Load Data
@st.cache_data
def load_data():
    with open('refined_reviews_advanced.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

data = load_data()
df = pd.DataFrame(data)

# === Gemini AI Logic ===
def generate_ai_report(df):
    """
    í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Geminiì—ê²Œ ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    # 1. Try Streamlit Secrets (Cloud)
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        # 2. Fallback to Environment Variable (Local .env)
        api_key = os.getenv("GEMINI_API_KEY")

    if not api_key or api_key == "YOUR_API_KEY_HERE":
        return None
    
    genai.configure(api_key=api_key)
    # Using gemini-1.5-flash for speed and stability
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    # 1. Prepare Prompt
    total_reviews = len(df)
    avg_rating = df['ë³„ì '].astype(int).mean()
    
    # Extract Tags
    all_tags = []
    for tags in df['íƒœê·¸_ABSA']:
        all_tags.extend(tags)
    tag_counts = pd.Series(all_tags).value_counts().head(5).to_string()
    
    prompt = f"""
    ë‹¹ì‹ ì€ í”„ë¡œí˜ì…”ë„í•œ ë°ì´í„° ë¶„ì„ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ ë Œí„°ì¹´ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 'ê²½ì˜ì§„ì„ ìœ„í•œ ìš”ì•½ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [Data Check]
    - ì´ ë¦¬ë·° ìˆ˜: {total_reviews}ê±´
    - í‰ê·  í‰ì : {avg_rating:.2f} / 5.0
    - ì£¼ìš” ì´ìŠˆ(íƒœê·¸ Top 5):
    {tag_counts}

    [Requirements]
    1. 'ğŸ“Š ì¢…í•© ì„±ê³¼', 'ğŸš¨ ì£¼ìš” ê°œì„ ì ', 'ğŸ’¡ ì•¡ì…˜ ì•„ì´í…œ' 3ê°€ì§€ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”.
    2. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ 'í•˜ì‹­ì‹œì˜¤'ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. ë¶ˆë › í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
    4. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error creating report: {str(e)}"

# Tabs
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ§© ë¶„ì„ ì›ë¦¬ (How it Works)", "ğŸ§ª ì‹¤ì‹œê°„ ì²´í—˜ (Live Demo)"])

# === Tab 1: Dashboard ===
with tab1:
    st.header("ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # --- AI Report Section ---
    st.markdown("### ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸")
    
    report_file = "ai_report.md"
    
    # Try Secrets then Env
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except:
        api_key = os.getenv("GEMINI_API_KEY")
    
    # Refresh Button
    force_refresh = st.button("ğŸ”„ ë¦¬í¬íŠ¸ ìµœì‹ í™” (Re-generate)")
    
    markdown_content = ""
    
    # 1. Load existing report if available and not forcing refresh
    if os.path.exists(report_file) and not force_refresh:
        with open(report_file, "r", encoding="utf-8") as f:
            markdown_content = f.read()
    
    # 2. Generate new report if missing or forced
    elif api_key and api_key != "YOUR_API_KEY_HERE":
        with st.spinner("Geminiê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 5~10ì´ˆ ì†Œìš”)"):
            markdown_content = generate_ai_report(df)
            if markdown_content:
                with open(report_file, "w", encoding="utf-8") as f:
                    f.write(markdown_content)
    
    # 3. Display Result
    if markdown_content:
        st.info(markdown_content)
    elif not api_key or api_key == "YOUR_API_KEY_HERE":
        st.warning("âš ï¸ Streamlit Cloudì˜ 'Secrets' ë˜ëŠ” ë¡œì»¬ `.env` íŒŒì¼ì— `GEMINI_API_KEY`ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    else:
        st.error("ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨. API Keyë‚˜ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.markdown("---") 

    # 1. Metrics
    col1, col2, col3 = st.columns(3)
    col1.metric("ì´ ë¶„ì„ ë¦¬ë·° ìˆ˜", f"{len(df)}ê±´")
    avg_rating = df['ë³„ì '].astype(int).mean()
    col2.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}ì ")
    
    # Flatten Tags for Analysis
    all_tags = []
    for tags in df['íƒœê·¸_ABSA']:
        all_tags.extend(tags)
    
    tag_counts = pd.Series(all_tags).value_counts().reset_index()
    tag_counts.columns = ['Tag', 'Count']
    
    # 2. Charts
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        st.subheader("AI ë¶„ì„ íƒœê·¸ ë¶„í¬")
        fig_tags = px.bar(tag_counts.head(10), x='Count', y='Tag', orientation='h', color='Count', title="Top 10 AI Tags")
        st.plotly_chart(fig_tags, use_container_width=True)
        
    with col_chart2:
        st.subheader("ë³„ì  ë¶„í¬")
        rating_counts = df['ë³„ì '].value_counts().sort_index()
        fig_rating = px.pie(values=rating_counts.values, names=rating_counts.index, title="Rating Distribution", hole=0.4)
        st.plotly_chart(fig_rating, use_container_width=True)

    # 3. Data Table
    st.subheader("ìƒì„¸ ë¦¬ë·° ë°ì´í„° (í•„í„°ë§ ê°€ëŠ¥)")
    st.dataframe(df)

# === Tab 2: How it Works ===
with tab2:
    st.header("SBERT Zero-Shot ABSA ì›ë¦¬")
    st.markdown("""
    ì´ ì‹œìŠ¤í…œì€ ë¯¸ë¦¬ í•™ìŠµëœ **SBERT (Sentence-BERT)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ê¹Šì´ ìˆê²Œ ì´í•´í•©ë‹ˆë‹¤.
    ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ, **'ì˜ë¯¸ì  ê±°ë¦¬(Semantic Distance)'**ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    """)
    
    col_desc1, col_desc2 = st.columns(2)
    with col_desc1:
        st.info("**1ë‹¨ê³„: ì†ì„± ì¶”ì¶œ (Aspect Extraction)**")
        st.markdown("- ë¦¬ë·°ì—ì„œ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì†ì„±(ì²­ê²°, ë¹„ìš©, ì‘ëŒ€ ë“±)ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.")
        st.markdown("- Fallback: ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì‚¬ì „ ì •ì˜ëœ í‚¤ì›Œë“œë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.")
        
    with col_desc2:
        st.success("**2ë‹¨ê³„: ê°ì • ë¶„ì„ (Zero-Shot Sentiment)**")
        st.markdown("- ì¶”ì¶œëœ ì†ì„±ì— ëŒ€í•´ **ê¸ì •/ë¶€ì • ì•µì»¤ ë¬¸ì¥**ê³¼ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
        st.code(f"ê¸ì • ì•µì»¤: {POS_ANCHOR}")
        st.code(f"ë¶€ì • ì•µì»¤: {NEG_ANCHOR}")
        st.markdown("ğŸ‘‰ ë” ê°€ê¹Œìš´ ìª½ì˜ ê°ì •ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤!")

# === Tab 3: Live Demo ===
with tab3:
    st.header("ğŸ§ª ì‹¤ì‹œê°„ AI ë¶„ì„ ì²´í—˜")
    st.markdown("ì§ì ‘ ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì—¬ AIê°€ ì–´ë–»ê²Œ ë¶„ì„í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    # Initialize Processor (Cached)
    @st.cache_resource
    def get_processor():
        return AdvancedReviewProcessor()
    
    processor = get_processor()
    
    # Input State Management
    if 'review_input' not in st.session_state:
        st.session_state.review_input = ""
    
    with st.form(key='analysis_form'):
        user_input = st.text_area("ë¦¬ë·° ë‚´ìš© ì…ë ¥:", key="review_input", height=100, placeholder="ì˜ˆì‹œ) ì§ì›ì€ ì¹œì ˆí•œë° ì°¨ëŠ” ì¢€ ë”ëŸ¬ì› ì–´ìš”.")
        submit_button = st.form_submit_button(label='AI ë¶„ì„ ì‹¤í–‰')
    
    if submit_button:
        with st.spinner("SBERT ëª¨ë¸ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # Process manually using the processor's methods
            # 1. Mock Aspect Extraction based on keywords (Demo logic)
            # For the demo, we replicate the process() logic simply
            tags = []
            
            # Using the process logic step-by-step
            # 1. Aspects
            from advanced_process_reviews import MOCK_KEYWORDS
            found_aspects = []
            for cat, kws in MOCK_KEYWORDS.items():
                for kw in kws:
                    if kw in user_input:
                        found_aspects.append(kw)
            
            # 2. Map & Sentiment
            results = []
            for aspect in found_aspects:
                cat = processor.map_category_sbert(aspect)
                if cat == "ê¸°íƒ€": continue
                
                sentiment = processor.analyze_sentiment_sbert(user_input, cat, aspect_keyword=aspect)
                tag_str = f"{cat}({sentiment})"
                if tag_str not in tags:
                    tags.append(tag_str)
                    results.append({"ì†ì„± í‚¤ì›Œë“œ": aspect, "íƒ€ê²Ÿ ë¬¸ì¥": f"...{aspect}...", "ì¹´í…Œê³ ë¦¬": cat, "ê°ì •": sentiment})
            
            # PII Check
            masked_input = user_input
            import re
            phone_pattern = r'010-\d{4}-\d{4}'
            if re.search(phone_pattern, masked_input):
                 masked_input = re.sub(phone_pattern, '010-****-****', masked_input)
                 st.warning("âš ï¸ ê°œì¸ì •ë³´(ì „í™”ë²ˆí˜¸)ê°€ ê°ì§€ë˜ì–´ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            st.markdown("### ë¶„ì„ ê²°ê³¼")
            st.subheader(f"ğŸ·ï¸ íƒœê·¸: {tags}")
            
            if results:
                st.table(pd.DataFrame(results))
            else:
                st.info("ê²€ì¶œëœ ì£¼ìš” ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            st.markdown("---")
            st.markdown("**ìµœì¢… ì €ì¥ë  í…ìŠ¤íŠ¸ (PII ë§ˆìŠ¤í‚¹ ì ìš©)**")
            st.code(masked_input)
